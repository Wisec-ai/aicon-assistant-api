# AICON Assistant API

**Microservicio de agente conversacional inteligente basado en RAG para ImmobAI**

## ğŸ“‹ DescripciÃ³n

El **AICON Assistant API** es un servicio core de conversaciÃ³n que forma parte de la arquitectura de microservicios de **ImmobAI** (plataforma inmobiliaria inteligente). Este servicio implementa un sistema de chat avanzado utilizando **RAG** (Retrieval Augmented Generation) para responder preguntas de usuarios basÃ¡ndose en documentaciÃ³n especÃ­fica de inmobiliarias.

### Contexto en ImmobAI

Este servicio se integra con la funcionalidad **"Chatea con tu data"** de la plataforma ImmobAI, permitiendo a inmobiliarias:

- ğŸ“„ Consultar documentaciÃ³n interna mediante chat inteligente
- ğŸ” Obtener respuestas precisas basadas en brochures, caracterÃ­sticas de proyectos y documentaciÃ³n tÃ©cnica
- ğŸ’¬ Mantener historial de conversaciones contextuales
- ğŸ¯ Personalizar respuestas segÃºn el catÃ¡logo de cada inmobiliaria

### Flujo de OperaciÃ³n

```
Usuario â†’ Pregunta â†’ AICON Assistant API
                         â†“
         [1] BÃºsqueda RAG (Vertex AI Search)
                         â†“
         [2] GeneraciÃ³n con Gemini 1.5 Pro
                         â†“
         [3] Streaming de respuesta
                         â†“
              Usuario recibe respuesta
```

## âœ¨ CaracterÃ­sticas Principales

### ğŸ§  Inteligencia Artificial

- **RAG Algorithm**: BÃºsqueda semÃ¡ntica en documentos almacenados
- **LLM**: Google Gemini 1.5 Pro-002 para generaciÃ³n de respuestas
- **Streaming**: Respuestas en tiempo real vÃ­a Server-Sent Events
- **Contextual**: Utiliza historial de conversaciÃ³n y documentos relevantes

### ğŸ“š GestiÃ³n de Documentos

- Subida de documentos vÃ­a presigned URLs
- IndexaciÃ³n automÃ¡tica en Vertex AI Search (Discovery Engine)
- BÃºsqueda semÃ¡ntica en brochures, PDFs, y documentaciÃ³n tÃ©cnica
- Soporte multi-formato: PDF, DOCX, TXT, MD, HTML

### ğŸ”„ GestiÃ³n de Sesiones

- Sesiones persistentes por usuario
- Historial completo de conversaciones
- Tracking de preguntas y respuestas
- IdentificaciÃ³n por email

### âš¡ Performance

- Streaming en tiempo real
- BÃºsqueda optimizada con Ã­ndices semÃ¡nticos
- Deployed en Google Cloud Run
- Auto-scaling (1-10 instancias)
- Concurrencia de hasta 80 requests por instancia

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos

- Python 3.10+
- Google Cloud Project con Vertex AI habilitado
- Vertex AI Search (Discovery Engine) Data Store configurado
- Service Account con permisos necesarios

### InstalaciÃ³n Local

```bash
# 1. Clonar repositorio
git clone <repository-url>
cd aicon-assistant-api

# 2. Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Configurar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales

# 5. Ejecutar migraciones
python manage.py migrate

# 6. Iniciar servidor
python manage.py runserver
```

El servidor estarÃ¡ disponible en `http://localhost:8000`

### Docker

```bash
# Build
docker build -t aicon-assistant-api:latest .

# Run
docker run -d \
  -p 8080:8080 \
  -e PROJECT_ID=your-project-id \
  -e REGION=us-east4 \
  -e DATA_STORE_ID=your-datastore-id \
  aicon-assistant-api:latest
```

## ğŸ“š DocumentaciÃ³n

DocumentaciÃ³n completa disponible en la carpeta `/docs`:

ğŸ“– **[Ãndice de DocumentaciÃ³n](docs/README.md)** - GuÃ­a de navegaciÃ³n

- **[Arquitectura](docs/ARQUITECTURA.md)** - DiseÃ±o del sistema, componentes y flujos de datos
- **[ConfiguraciÃ³n](docs/CONFIGURACION.md)** - Setup, deployment y configuraciÃ³n avanzada
- **[API](docs/API.md)** - DocumentaciÃ³n completa de endpoints REST

## ğŸ› ï¸ Stack TecnolÃ³gico

### Backend
- **Framework**: Django 5.1.6 + Django REST Framework
- **Lenguaje**: Python 3.10
- **ORM**: Django ORM
- **Base de Datos**: SQLite (dev) / PostgreSQL (prod)

### IA & Machine Learning
- **LLM**: Google Gemini 1.5 Pro-002
- **RAG**: Langchain + Vertex AI Search
- **Search**: Google Discovery Engine
- **Streaming**: Vertex AI Generative Models

### Cloud & DevOps
- **Plataforma**: Google Cloud Platform
- **Compute**: Cloud Run (Knative)
- **CI/CD**: Cloud Build
- **Storage**: Cloud Storage
- **Container**: Docker

### Principales LibrerÃ­as
```
langchain-google-community==1.0.7   # Vertex AI Search
langchain-google-genai==1.0.8       # Gemini Models
langchain-google-vertexai==1.0.8    # Vertex AI Integration
google-cloud-discoveryengine==0.12.0 # Document Search
google-cloud-storage==2.18.0        # Cloud Storage
djangorestframework==3.15.2         # REST API
```

## ğŸ“ Estructura del Proyecto

```
aicon-assistant-api/
â”œâ”€â”€ agent/                          # MÃ³dulo principal de conversaciÃ³n
â”‚   â”œâ”€â”€ application/service/        # Servicios de negocio
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”œâ”€â”€ constants/              # Prompts y constantes
â”‚   â”‚   â”œâ”€â”€ entities/               # DTOs y entidades
â”‚   â”‚   â””â”€â”€ repository/             # Clientes RAG y AI
â”‚   â”œâ”€â”€ views/                      # API endpoints
â”‚   â””â”€â”€ models.py                   # Models de BD
â”œâ”€â”€ commons/                        # Utilidades compartidas
â”‚   â””â”€â”€ domain/
â”‚       â”œâ”€â”€ constants/              # Variables de entorno
â”‚       â”œâ”€â”€ repository/             # Clientes Cloud
â”‚       â””â”€â”€ utils/                  # Utilidades generales
â”œâ”€â”€ documents/                      # GestiÃ³n de documentos
â”‚   â”œâ”€â”€ application/
â”‚   â”œâ”€â”€ domain/models/
â”‚   â””â”€â”€ views.py
â”œâ”€â”€ backend_aicon_assistant/        # Config Django
â”‚   â”œâ”€â”€ settings.py
â”‚   â””â”€â”€ urls.py
â”œâ”€â”€ docs/                           # DocumentaciÃ³n
â”‚   â”œâ”€â”€ ARQUITECTURA.md
â”‚   â”œâ”€â”€ CONFIGURACION.md
â”‚   â””â”€â”€ API.md
â”œâ”€â”€ Dockerfile                      # Imagen Docker
â”œâ”€â”€ requirements.txt                # Dependencias
â””â”€â”€ service.yaml                    # Config Cloud Run
```

## ğŸ¯ Uso BÃ¡sico de la API

### 1. Crear SesiÃ³n

```bash
curl -X POST https://your-domain/aicon/chat/generate-session \
  -H "Content-Type: application/json" \
  -d '{"email": "user@example.com"}'
```

Respuesta:
```json
{
  "session_id": "550e8400-e29b-41d4-a716-446655440000"
}
```

### 2. Hacer Pregunta (Streaming)

```bash
curl -X POST https://your-domain/aicon/chat/streaming-chat \
  -H "Content-Type: application/json" \
  -N \
  -d '{
    "question": "Â¿CuÃ¡les son las caracterÃ­sticas del modelo Estudio?",
    "session_id": "550e8400-e29b-41d4-a716-446655440000"
  }'
```

Respuesta (streaming):
```json
{"raw_response": "SegÃºn la documentaciÃ³n disponible..."}
{"raw_response": "el modelo Estudio cuenta con..."}
...
{"conversation_id": "660e8400-e29b-41d4-a716-446655440000"}
```

Ver [documentaciÃ³n completa de API](docs/API.md) para mÃ¡s ejemplos.

## ğŸ” ConfiguraciÃ³n

### Variables de Entorno Requeridas

```bash
PROJECT_ID=your-gcp-project
REGION=us-east4
DATA_STORE_ID=your-datastore-id
DATA_STORE_LOCATION=global
GCLOUD_STORAGE_BUCKET=your-bucket
GCLOUD_STORAGE_FOLDER=/documents
DOCUMENT_BUCKET=your-docs-bucket
```

Ver [guÃ­a de configuraciÃ³n](docs/CONFIGURACION.md) para setup detallado.

## ğŸš¢ Deployment

### Google Cloud Run

El servicio estÃ¡ configurado para deploy automÃ¡tico en Cloud Run:

```bash
# Trigger Cloud Build
gcloud builds submit --config=cloudbuild.yaml

# O push a rama main para CI/CD automÃ¡tico
git push origin main
```

**Especificaciones de producciÃ³n**:
- CPU: 1 vCPU
- Memoria: 1GB
- Max instancias: 10
- Timeout: 30s
- Concurrencia: 80 requests/instancia

Ver [configuraciÃ³n de deployment](docs/CONFIGURACION.md) para mÃ¡s detalles.

## ğŸ§ª Testing

```bash
# Tests unitarios
python manage.py test

# Tests con cobertura
coverage run --source='.' manage.py test
coverage report
```

## ğŸ“Š Monitoring

El servicio envÃ­a logs automÃ¡ticamente a Cloud Logging:

```bash
# Ver logs en tiempo real
gcloud logging tail "resource.type=cloud_run_revision"
```

## ğŸ”„ Arquitectura de Microservicios

Este servicio es parte del ecosistema ImmobAI:

```
Frontend Angular
    â†“
Backend Principal â†â†’ AICON Assistant API â†â†’ Vertex AI Search
    â†“                        â†“
WhatsApp Assistant      Cloud Storage
```

Ver [documentaciÃ³n de arquitectura](docs/ARQUITECTURA.md) para detalles completos.

## ğŸ‘¥ Equipo

**AICON** - Startup de Inteligencia Artificial

- **Cristian Gomez** - cgluni16@gmail.com
- **Johann Gonzales** - jgonzalesinca15@gmail.com

## ğŸ“ Contacto

**Equipo**: AICON  
**Email**: cgluni16@gmail.com, jgonzalesinca15@gmail.com

## ğŸ™ Agradecimientos

- Google Cloud Platform
- Langchain Team
- Django Community
- Vertex AI Team

## ğŸ“ Licencia

Proprietary - Todos los derechos reservados

---

**Nota**: Este es un microservicio core para ImmobAI. Para mÃ¡s informaciÃ³n sobre la plataforma completa, consultar los repositorios relacionados.

